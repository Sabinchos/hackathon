В ходе выполнения работы была поставлена цель — выяснить, помогает ли применение открытой языковой модели (LLM) повысить качество тематической классификации отзывов жильцов управляющей компании. 

Рассматриваем две стратегии:
1. **↑ Увеличение обучающей выборки** путём генерации новых отзывов на основе существующих.  
2. **↑ Обогащение текстов** — расширение каждого реального отзыва релевантными комментариями (добавочный контекст).

Качество измеряем метрикой *macro-F₁*.

### Поставленные задачи
origin dataset:
1. **Анализ исходных данных**  
   - Анализ и подготовка исходного набора данных.  
   - Оценка текущей *F-меры* с моделью **k-NN (k = 5)** на эмбеддингах **LaBSE** ((macro) F-мера = 0.672).
2. **Увеличение обучающей выборки**  
   - Генерирование дополнительных отзывов с помощью GPT-3.5 (три пронта).  
   - Сравнение *F-мер*.  
3. **Обогащение текстов**  
   - Расширение существующих отзывов с помощью генерации (GPT-3.5) продолжения отзывов.
   - Сравнение *F-мер*.
4. **Вывод**  
   - В виду низкого показателя качества классификации было принято решение переразметить исходный набор данных.
   
relabeled dataset:
1. **Анализ переразмеченных данных**  
   - Подготовка пререразмченного набора данных.  
   - Оценка текущей *F-меры* с моделью **k-NN (k = 5)** на эмбеддингах **LaBSE** ((macro) F-мера = 0.795).  
2. **Увеличение обучающей выборки**  
   - Генерирование дополнительных отзывов с помощью GPT-3.5 (четыре пронта) и GigaChat.  
   - Сравнение *F-мер*.  
3. **Обогащение текстов**  
   - Расширение существующих отзывов с помощью генерации (GPT-3.5) продолжения отзывов.
   - Сравнение *F-мер*.
4. **Вывод**

Origin dataset (исходный набор данных)

| # | Подход | Источник синтетики / промпт | macro-F₁ |
|---|--------|----------------------------|----------:|
| 0 | Базовая модель (LaBSE + k-NN = 5) | — | **0.672** |
| 1 |  · GPT-3.5, промпт #1  | synthetic¹ | 0.674 |
| 2 |  · GPT-3.5, промпт #2 | synthetic² |  0.672 |
| 3 |  · GPT-3.5, промпт #3 | synthetic³ | 0.668 |
| 4 |  · GPT-3.5, удлинение отзывов | enriched | **0.685**|


Relabeled dataset (переразмеченный набор данных)

| # | Подход | Источник синтетики / промпт | macro-F₁ |
|---|--------|----------------------------|----------:|
| 0 | Базовая модель (LaBSE + k-NN = 5) | — | **0.795** |
| 1 |  · GPT-3.5, промпт #1  | synthetic¹ | 0.788 |
| 2 |  · GPT-3.5, промпт #2 | synthetic² | 0.786 |
| 3 |  · GPT-3.5, промпт #3 | synthetic³ | 0.790 |
| 4 |  · GPT-3.5, промпт #4 | synthetic⁴ | **0.812** |
| 5 |  · GigaChat-2  | syntheticGigaChat | 0.788 |
| 6 |  · GPT-3.5, удлинение отзывов | enriched | 0.731 |
 
* Переразметка улучшила macro-F₁.
* Чрезмерное расширение без контроля может снизить качество.
* Использование генеративных моделей для генерации синтетических данных - имеет смысл, так как может увеличить качество классификации, когда мы располагаем малым объемом данных для обучения.
* Использование моделей для дописывания текста отзыва не очень хорошая идея для данной задачи классификации текстовых данных. 
